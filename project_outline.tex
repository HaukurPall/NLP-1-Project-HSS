

1. Make  work KenLM
Get to work with our corpus
See: http://thegrandjanitor.com/2015/12/28/using-arpa-lm-with-python/
Finished by: 12th of Nov

2. FF (Bengio)
Word embeddings
http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf
-Have perplexity measurement working
-19th of Nov

3. RAN
https://arxiv.org/abs/1705.07393


Idea:
RAN should handle histories better. We might want to measure this.
Do FF handle P(word) better than the RAN?

Background.

When estimating whether a sentence is a valid sentence of a particular language, language models come in.
Given a corpus, language models compute a probability over a sentence, the higher probability, the more likely the sentence is to be a part of that language. Most common approach to estimate that probability are language models called N-grams. The most simple N-grams compute the probability of word using MLE. An N-gram makes a simplifying assumption s.t. the probability of a sentence is not dependent on all words in the sentence, but only the N-1 words in front. We then multiply the probabilities of each word together to compute the probability of a sentence. This simple approach lends it self to issues, as we estimate the probabilites of a sentence over a corpus, which is sparse and might not contain all words which we might need to evaluate, but are still valid sentences of a language. Our simple N-gram will give unseen words probability of 0, therefore the sentence will receive a probability of 0. To avoid this problem, we use smoothing s.t. unseen words (and their histories) will receive a positive value. [References to N-grams]

Dataset: https://github.com/pytorch/examples/tree/master/word_language_model/data/penn

We looked at the KenLM N-gram model to begin with[Reference to that]. It uses Kneser-Ney smoothing smoothing and is particularly fast. We used it as our baseline.

A background section, in which you explain what is language modelling, what kind of language models you studied, and what is the problem you focus on. To write this background section, you can use the suggested papers, but also add papers;
A summary of the relevant literature
A description of your replication;
A formal discription of your model(s) and changes/improvements you made compared to the literature
Analysis of your results
A conclusion


For the report, we suggest that use the following structure:

Title, members of the group, student ids
Abstract (1 paragraph: the main idea and a key finding)
Introduction (max 2 pages):
Description of the problem area and the problem itself
What is the research question / goal?
Why is this an important / meaningful / interesting problem to consider?
The very basic idea of the approach and why this is a reasonable approach for this problem?
Problem: (roughly 1-2 pages)
Explain the problem; what kind of assumptions / observations you have about the problem
Approach (roughly 2-3 pages)
Explain the model; if any important assumptions are made at this stage, explain why they are reasonable or necessary
Explain learning / inference algorithms
Explaining (perhaps briefly) any necessary preprocessing / postprocesing / data acquisition stages (maybe earlier, depending on the project; may also move to the experimental section)
Experiments / Empirical evaluation (roughly 2-3 pages)
Any details about experiments (dataset sizes, parameter selection, etc)
Results
Analysis (discussion of results / visualization / findings / etc)
Discussion and Conclusions (0.5 – 1 page)
Refer to the research questions you defined in your introduction.
Any related work you are aware of?
Challenges you observed?
“Future work” (you do not need to do this work really J, but what would you change in the model / what experiments you would run / etc, if you would have a chance to do this? What other people should look into?
Any thoughts / observation / wider implications
Team responsibilities (1 paragraph)
Who did what
